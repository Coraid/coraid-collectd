#!/usr/bin/env bash
#
# Publish pool and dataset latency, bandwidth, and IOPS to collectd.
# Suitable for illumos, OpenSolaris, and Solaris 11 derivatives.
#
# Data is collected per-pool and per-pool+dataset. The pool and datasets
# are referenced by their guid (zpool get guid poolname) as hex numbers.
# This avoids ambiguity. Cross-reference between poolname or datasetname
# and its guid is left as an exercise for the consumer.
#
# General output format:
#    $(uname -n)/ZFS-VOps-POOLGUID/gauge-([rw]lat|[rw]iops|[rw]bw)
#    $(uname -n)/ZFS-VOps-POOLGUID-DATASETGUID/gauge-([rw]lat|[rw]iops|[rw]bw)
#
# All metrics are normalized to per-second, independent of the sample interval.
#  [rw]lat = [read|write] average latency in microseconds
#  [rw]iops = [read|write] IOPS
#  [rw]bw = [read|write] bandwidth in bytes/sec
#
# Note: it is expected that the dtrace can fail, in which case this script will
# automatically try to restart the dtrace collector.
#
# Debug hint: set the COLLECTD_CMD environment variable to "cat" and the data
# is sent to stdout rather than into a collectd unixsock.
#
# Copyright 2015 Coraid, Inc.
#
# MIT License
# ===========
# Permission is hereby granted, free of charge, to any person obtaining a copy of
# this software and associated documentation files (the "Software"), to deal in
# the Software without restriction, including without limitation the rights to
# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
# of the Software, and to permit persons to whom the Software is furnished to do
# so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

export PATH=/usr/sbin:/usr/bin
if [[ $(uname -s) != "SunOS" ]]; then
    echo "error: unsupported OS: $(uname -s)"
    exit 1
fi

UNIXSOCK="/opt/collectd/var/run/collectd-unixsock"
case $(uname -v) in
    8.*)   # CorOS 8
        if [[ $(zonename) == "global" ]]; then
            AZ_UUID=$(vmadm list -H -o uuid alias=admin | head -1)
            UNIXSOCK="/cordpool/${AZ_UUID}/root${UNIXSOCK}"
        fi            
        ;;
    11.*)  # Solaris 11
        ;;
    *)
        echo "error: unsupported OS version $(uname -v)"
        exit 1
esac

if [[ -z "$COLLECTD_CMD" ]]; then
    if [[ ! -S ${UNIXSOCK} ]]; then
        echo "error: cannot locate collectd socket: $UNIXSOCK"
        exit 1
    fi
    COLLECTD_CMD="nc -U $UNIXSOCK"
    # send nc stdout to /dev/null
    exec 3<>/dev/null
else
    # if overriding COLLECTD_CMD, send stdout to stdout
    exec 3>&1
fi
NODENAME=${NODENAME:=$(uname -n)}
INTERVAL=${INTERVAL:=60}  # sampling interval in seconds
STARTTIME=$(date +%s)

while true
do
/usr/sbin/dtrace -Cn '
/*
 * trace read/write requests on a per-pool and per-dataset basis
 */
#pragma D option quiet
#pragma D option switchrate=10hz
#pragma D option dynvarsize=4m
inline int INTERVAL = '$INTERVAL';  /* seconds */
inline int MAX_INTERVALS = 50;      /* exit after this number of intervals */

BEGIN
{
    /*
     * Table for int to hex string conversion
     * This is needed because dtrace aggregations accept strings as keys,
     * but there is no sprintf(), so we build a hex string using brute force
     */
    hex[0]  = "0"; hex[1]  = "1"; hex[2]  = "2"; hex[3]  = "3";
    hex[4]  = "4"; hex[5]  = "5"; hex[6]  = "6"; hex[7]  = "7";
    hex[8]  = "8"; hex[9]  = "9"; hex[10] = "a"; hex[11] = "b";
    hex[12] = "c"; hex[13] = "d"; hex[14] = "e"; hex[15] = "f";

    interval_count = 0;
}

fbt::zfs_read:entry,
fbt::zfs_write:entry
{
    this->spa = ((znode_t *)args[0]->v_data)->z_zfsvfs->z_os->os_spa;
    self->pool_guid = this->spa->spa_root_vdev != NULL?
        this->spa->spa_root_vdev->vdev_guid :
        this->spa->spa_load_guid;
    this->ds_dbuf = ((znode_t *)args[0]->v_data)->z_zfsvfs->z_os->os_dsl_dataset->ds_dbuf;
    self->dataset_guid = ((dsl_dataset_phys_t *)this->ds_dbuf->db_data)->ds_guid;
    self->bytes = args[1]->uio_resid;
    self->ts = timestamp;
}

/* convert the pool guid from uint64 to string of hex and cache the result */
fbt::zfs_read:entry,
fbt::zfs_write:entry
/pool_id[self->pool_guid] == NULL/
{
    this->s = strjoin(hex[(self->pool_guid >> 60) & 0xf], hex[(self->pool_guid >> 56) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 52) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 48) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 44) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 40) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 36) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 32) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 28) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 24) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 20) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 16) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 12) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 8) & 0xf]);
    this->s = strjoin(this->s, hex[(self->pool_guid >> 4) & 0xf]);
    this->s = strjoin(this->s, hex[self->pool_guid & 0xf]);
    pool_id[self->pool_guid] = this->s;
}

/* convert the dataset guid from uint64 to string of hex and cache the result */
fbt::zfs_read:entry,
fbt::zfs_write:entry
/dataset_id[self->dataset_guid] == NULL/
{
    this->s = strjoin(hex[(self->dataset_guid >> 60) & 0xf], hex[(self->dataset_guid >> 56) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 52) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 48) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 44) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 40) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 36) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 32) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 28) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 24) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 20) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 16) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 12) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 8) & 0xf]);
    this->s = strjoin(this->s, hex[(self->dataset_guid >> 4) & 0xf]);
    this->s = strjoin(this->s, hex[self->dataset_guid & 0xf]);
    dataset_id[self->dataset_guid] = this->s;
}

fbt::zfs_read:return,
fbt::zfs_write:return
/self->ts/
{
    this->deltat = timestamp - self->ts;

    @pool_avg_lat[pool_id[self->pool_guid], "lat"] = avg(this->deltat);
    @dataset_avg_lat[pool_id[self->pool_guid], dataset_id[self->dataset_guid], "lat"] = 
        avg(this->deltat);
    this->op = probefunc == "zfs_read" ? "rlat" : "wlat";
    @pool_avg_lat[pool_id[self->pool_guid], this->op] = avg(this->deltat);
    @dataset_avg_lat[pool_id[self->pool_guid], dataset_id[self->dataset_guid], this->op] = 
        avg(this->deltat);

    @pool_bw[pool_id[self->pool_guid], "bw"] = sum(self->bytes);
    @dataset_bw[pool_id[self->pool_guid], dataset_id[self->dataset_guid], "bw"] = 
        sum(self->bytes);
    this->op = probefunc == "zfs_read" ? "rbw" : "wbw";
    @pool_bw[pool_id[self->pool_guid], this->op] = sum(self->bytes);
    @dataset_bw[pool_id[self->pool_guid], dataset_id[self->dataset_guid], this->op] = 
        sum(self->bytes);

    @pool_iops[pool_id[self->pool_guid], "iops"] = count();
    @dataset_iops[pool_id[self->pool_guid], dataset_id[self->dataset_guid], "iops"] = count();
    this->op = probefunc == "zfs_read" ? "riops" : "wiops";
    @pool_iops[pool_id[self->pool_guid], this->op] = count();
    @dataset_iops[pool_id[self->pool_guid], dataset_id[self->dataset_guid], this->op] = count();
    self->pool_guid = 0;
    self->dataset_guid = 0;
    self->bytes = 0;
    self->ts = 0;
}

tick-'$INTERVAL'sec
{
    /* convert average latency to microseconds */
    normalize(@pool_avg_lat, 1000);
    normalize(@dataset_avg_lat, 1000);

    /* normalize bandwidth from bytes to bytes/sec */
    normalize(@pool_bw, INTERVAL);
    normalize(@dataset_bw, INTERVAL);

    /* normalize counts to per-second (IOPS) */
    normalize(@pool_iops, INTERVAL);
    normalize(@dataset_iops, INTERVAL);

    printa("ZFS-VOps-%s/gauge-%s %@d\n", @pool_avg_lat);
    printa("ZFS-VOps-%s/gauge-%s %@d\n", @pool_bw);
    printa("ZFS-VOps-%s/gauge-%s %@d\n", @pool_iops);

    printa("ZFS-VOps-%s-%s/gauge-%s %@d\n", @dataset_avg_lat);
    printa("ZFS-VOps-%s-%s/gauge-%s %@d\n", @dataset_bw);
    printa("ZFS-VOps-%s-%s/gauge-%s %@d\n", @dataset_iops);
    
    trunc(@pool_avg_lat); trunc(@dataset_avg_lat);
    trunc(@pool_bw); trunc(@dataset_bw); trunc(@pool_iops); trunc(@dataset_iops);
    interval_start = timestamp;
    interval_count++;
}

tick-'$INTERVAL'sec
/interval_count > MAX_INTERVALS/
{
    exit(0);
}

END
{
    trunc(@pool_avg_lat); trunc(@dataset_avg_lat);
    trunc(@pool_bw); trunc(@dataset_bw); trunc(@pool_iops); trunc(@dataset_iops);
}' | while read metric value
    do
        # note: Solaris' printf builtin doesn't understand %(%s)T, so we efficiently 
        # calculate the current time as elapsed
        [[ -n "$metric" ]] && printf "PUTVAL \"%s/%s\" interval=%s %s:%s\n" \
            $NODENAME $metric $INTERVAL $(($STARTTIME + $SECONDS)) $value
    done | $COLLECTD_CMD >&3
done
